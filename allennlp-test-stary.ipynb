{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f1f432",
   "metadata": {},
   "source": [
    "### Allennlp-Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad415dbd",
   "metadata": {},
   "source": [
    "#### Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab713a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container and deploy to SageMaker's managed hosting environments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fec700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-28T06:39:26.679324Z",
     "start_time": "2022-10-28T06:39:26.668891Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Set up the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf39489c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting allennlp\n",
      "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 KB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonlines\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Collecting allennlp-models\n",
      "  Downloading allennlp_models-2.10.1-py3-none-any.whl (464 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.5/464.5 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy\n",
      "  Downloading spacy-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flake8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (4.0.1)\n",
      "Collecting mypy==0.961\n",
      "  Downloading mypy-0.961-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.8/17.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: black in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (21.11b1)\n",
      "Requirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (6.2.5)\n",
      "Collecting pytest-cov\n",
      "  Downloading pytest_cov-4.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting pytest-forked\n",
      "  Downloading pytest_forked-1.4.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting pytest-xdist\n",
      "  Downloading pytest_xdist-3.0.2-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: coverage in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (6.3.2)\n",
      "Collecting codecov\n",
      "  Downloading codecov-2.1.12-py2.py3-none-any.whl (16 kB)\n",
      "Collecting flaky\n",
      "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
      "Collecting ruamel.yaml\n",
      "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydoc-markdown<5.0.0,>=4.0.0\n",
      "  Downloading pydoc_markdown-4.6.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting databind.core\n",
      "  Downloading databind.core-2.0.7-py3-none-any.whl (24 kB)\n",
      "Collecting docspec<2.0.0\n",
      "  Downloading docspec-1.3.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting docspec-python<2.0.0\n",
      "  Downloading docspec_python-1.3.0-py3-none-any.whl (12 kB)\n",
      "Collecting mkdocs==1.3.0\n",
      "  Downloading mkdocs-1.3.0-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mkdocs-material<8.4.0,>=5.5.0\n",
      "  Downloading mkdocs_material-8.3.9-py2.py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown-include==0.6.0\n",
      "  Downloading markdown-include-0.6.0.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting twine>=1.11.0\n",
      "  Downloading twine-4.0.1-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r requirements.txt (line 56)) (59.4.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r requirements.txt (line 57)) (0.37.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mypy==0.961->-r requirements.txt (line 13)) (4.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mypy==0.961->-r requirements.txt (line 13)) (1.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mypy==0.961->-r requirements.txt (line 13)) (0.4.3)\n",
      "Collecting ghp-import>=1.0\n",
      "  Downloading ghp_import-2.1.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: Jinja2>=2.10.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mkdocs==1.3.0->-r requirements.txt (line 48)) (3.0.3)\n",
      "Collecting pyyaml-env-tag>=0.1\n",
      "  Downloading pyyaml_env_tag-0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting mergedeep>=1.3.4\n",
      "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: watchdog>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mkdocs==1.3.0->-r requirements.txt (line 48)) (2.1.6)\n",
      "Requirement already satisfied: click>=3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mkdocs==1.3.0->-r requirements.txt (line 48)) (8.0.3)\n",
      "Collecting Markdown>=3.2.1\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mkdocs==1.3.0->-r requirements.txt (line 48)) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mkdocs==1.3.0->-r requirements.txt (line 48)) (21.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mkdocs==1.3.0->-r requirements.txt (line 48)) (5.4.1)\n",
      "Collecting traitlets>5.1.1\n",
      "  Downloading traitlets-5.5.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting base58>=2.1.1\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting lmdb>=1.2.1\n",
      "  Downloading lmdb-1.3.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.9/305.9 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4.0.0,>=3.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (3.19.1)\n",
      "Collecting termcolor==1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch<1.13.0,>=1.10.0\n",
      "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m814.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.7.3\n",
      "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jsonnet>=0.10.0\n",
      "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.6/593.6 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece>=0.1.96\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (4.62.3)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cached-path<1.2.0,>=1.1.3\n",
      "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (1.0.1)\n",
      "Collecting requests>=2.28\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting fairscale==0.4.6\n",
      "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock<3.8,>=3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (3.4.0)\n",
      "Collecting typer>=0.4.1\n",
      "  Downloading typer-0.6.1-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: more-itertools>=8.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (8.12.0)\n",
      "Collecting h5py>=3.6.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision<0.14.0,>=0.8.1\n",
      "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wandb<0.13.0,>=0.10.0\n",
      "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.21,>=4.1\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (0.3.4)\n",
      "Requirement already satisfied: nltk>=3.6.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from allennlp->-r requirements.txt (line 3)) (3.7)\n",
      "Collecting numpy>=1.21.4\n",
      "  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonlines->-r requirements.txt (line 4)) (21.2.0)\n",
      "Collecting py-rouge==1.1\n",
      "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m849.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.9/441.9 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting conllu==4.4.2\n",
      "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting word2number>=1.1\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.6/492.6 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.14\n",
      "  Downloading thinc-8.0.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.1/671.1 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Downloading spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting typer>=0.4.1\n",
      "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from flake8->-r requirements.txt (line 10)) (2.8.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from flake8->-r requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from flake8->-r requirements.txt (line 10)) (2.4.0)\n",
      "Requirement already satisfied: regex>=2021.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from black->-r requirements.txt (line 16)) (2021.11.10)\n",
      "Requirement already satisfied: pathspec<1,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from black->-r requirements.txt (line 16)) (0.9.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from black->-r requirements.txt (line 16)) (2.3.0)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pytest->-r requirements.txt (line 19)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pytest->-r requirements.txt (line 19)) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pytest->-r requirements.txt (line 19)) (1.11.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pytest->-r requirements.txt (line 19)) (0.10.2)\n",
      "Collecting execnet>=1.1\n",
      "  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.6\n",
      "  Downloading ruamel.yaml.clib-0.2.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (555 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m555.3/555.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydoc-markdown<5.0.0,>=4.0.0\n",
      "  Downloading pydoc_markdown-4.6.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading pydoc_markdown-4.6.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading pydoc_markdown-4.6.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading pydoc_markdown-4.5.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nr.fs<2.0.0,>=1.6.0\n",
      "  Downloading nr.fs-1.6.3-py2.py3-none-any.whl (13 kB)\n",
      "Collecting docstring-parser<0.12,>=0.11\n",
      "  Downloading docstring_parser-0.11.tar.gz (22 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nr.stream<0.2.0,>=0.1.2\n",
      "  Downloading nr.stream-0.1.2-py3-none-any.whl (6.3 kB)\n",
      "Collecting databind<2.0.0,>=1.5.0\n",
      "  Downloading databind-1.5.3-py3-none-any.whl (1.6 kB)\n",
      "Collecting typeapi<0.3.0,>=0.1.5\n",
      "  Downloading typeapi-0.2.2-py3-none-any.whl (12 kB)\n",
      "Collecting Deprecated<2.0.0,>=1.2.12\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting nr.util<1.0.0,>=0.8.8\n",
      "  Downloading nr.util-0.8.12-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.3/90.3 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting databind.core\n",
      "  Downloading databind.core-1.5.3-py3-none-any.whl (35 kB)\n",
      "Collecting databind.json<2.0.0,>=1.0.0\n",
      "  Downloading databind.json-1.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting docspec-python<2.0.0\n",
      "  Downloading docspec_python-1.2.0-py3-none-any.whl (14 kB)\n",
      "Collecting pygments>=2.12\n",
      "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pymdown-extensions>=9.4\n",
      "  Downloading pymdown_extensions-9.7-py3-none-any.whl (218 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 KB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mkdocs-material-extensions>=1.0.3\n",
      "  Downloading mkdocs_material_extensions-1.1-py3-none-any.whl (7.9 kB)\n",
      "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting readme-renderer>=35.0\n",
      "  Downloading readme_renderer-37.2-py3-none-any.whl (14 kB)\n",
      "Collecting rich>=12.0.0\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 KB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 55)) (1.26.8)\n",
      "Requirement already satisfied: keyring>=15.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 55)) (23.4.0)\n",
      "Collecting rfc3986>=1.4.0\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from twine>=1.11.0->-r requirements.txt (line 55)) (1.8.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cached-path<1.2.0,>=1.1.3->allennlp->-r requirements.txt (line 3)) (1.24.96)\n",
      "Collecting google-cloud-storage<3.0,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.5.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from Deprecated<2.0.0,>=1.2.12->databind.core->-r requirements.txt (line 44)) (1.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from ghp-import>=1.0->mkdocs==1.3.0->-r requirements.txt (line 48)) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata>=4.3->mkdocs==1.3.0->-r requirements.txt (line 48)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from Jinja2>=2.10.2->mkdocs==1.3.0->-r requirements.txt (line 48)) (2.0.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 55)) (0.7.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 55)) (3.3.1)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk>=3.6.5->allennlp->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nr.fs<2.0.0,>=1.6.0->pydoc-markdown<5.0.0,>=4.0.0->-r requirements.txt (line 43)) (1.16.0)\n",
      "Collecting nr.pylang.utils<1.0.0,>=0.1.0\n",
      "  Downloading nr.pylang.utils-0.1.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging>=20.5->mkdocs==1.3.0->-r requirements.txt (line 48)) (3.0.6)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: docutils>=0.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from readme-renderer>=35.0->twine>=1.11.0->-r requirements.txt (line 55)) (0.15.2)\n",
      "Requirement already satisfied: bleach>=2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from readme-renderer>=35.0->twine>=1.11.0->-r requirements.txt (line 55)) (4.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.28->allennlp->-r requirements.txt (line 3)) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.28->allennlp->-r requirements.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.28->allennlp->-r requirements.txt (line 3)) (2.0.8)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from scikit-learn>=1.0.1->allennlp->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from torchvision<0.14.0,>=0.8.1->allennlp->-r requirements.txt (line 3)) (9.0.1)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 KB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->-r requirements.txt (line 3)) (5.8.0)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets->allennlp-models->-r requirements.txt (line 5)) (2021.11.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets->allennlp-models->-r requirements.txt (line 5)) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets->allennlp-models->-r requirements.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets->allennlp-models->-r requirements.txt (line 5)) (7.0.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets->allennlp-models->-r requirements.txt (line 5)) (1.3.4)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from ftfy->allennlp-models->-r requirements.txt (line 5)) (0.2.5)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from bleach>=2.1.0->readme-renderer>=35.0->twine>=1.11.0->-r requirements.txt (line 55)) (0.5.1)\n",
      "Collecting botocore<1.28.0,>=1.27.96\n",
      "  Using cached botocore-1.27.96-py3-none-any.whl (9.3 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp->-r requirements.txt (line 3)) (0.6.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.13.0-py2.py3-none-any.whl (174 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 KB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 55)) (36.0.0)\n",
      "Collecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets->allennlp-models->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets->allennlp-models->-r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets->allennlp-models->-r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets->allennlp-models->-r requirements.txt (line 5)) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets->allennlp-models->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->datasets->allennlp-models->-r requirements.txt (line 5)) (2021.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 55)) (1.15.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 KB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<4.0.0,>=3.12.0\n",
      "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->-r requirements.txt (line 3)) (4.7.2)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine>=1.11.0->-r requirements.txt (line 55)) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->-r requirements.txt (line 3)) (0.4.8)\n",
      "Building wheels for collected packages: markdown-include, fairscale, termcolor, docstring-parser, jsonnet, word2number, sacremoses, promise, pathtools\n",
      "  Building wheel for markdown-include (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for markdown-include: filename=markdown_include-0.6.0-py3-none-any.whl size=4591 sha256=2484e42dc7b56d48b06928d6d2557da2529fec918565628fe7cccc224436f5ad\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/09/bd/75/0da88f9b483bef2205dcee1b0b2cc86d07060b4d370cb672bf\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307225 sha256=d41c95bf95fa123ff33e204a276f8df54631d576d7e77e2694f70d1df0454bb8\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/77/4c/a4/f6c0eec2ec5c8ffca075e62b0329801f862e1f1b71422f456b\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=6fe48492c1d0361c13a53c64c34c52ed96844753fd893c4f1df5b4f35b30f955\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for docstring-parser (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docstring-parser: filename=docstring_parser-0.11-py3-none-any.whl size=31514 sha256=ffbcb0d26de595be78e711e71f309a191037ca430c9d43b72337bda6bcbd97a0\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/db/99/e8/eb53b9eaed784d7ea1ef9794be129ef88e783d297939b33704\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp38-cp38-linux_x86_64.whl size=3973985 sha256=c5f8dcca89182b760cca944f95f0a6ec18bd185ed174590f95a5e2d8b6985c0f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/64/ec/56/de861aae102c449ade2378772abbf9eb7e9acfe9a80f3e6036\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5580 sha256=5628f4e9893c836fecb31a995bfc247191bcde2a214cdf5a02aeb6ae53d44eb2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/cb/f3/5a/d88198fdeb46781ddd7e7f2653061af83e7adb2a076d8886d6\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=eb0c12c2ebbae5166ca32c274413208a3d2e0e853875f9b34fae08de7ee62c36\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=74d9339d4c018f2632b95e88b96aeb3ba2660ace5ac2988391340fe62bc77892\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=ea9197963cc763b4015a5a93d09b2fe39ff7d0409298404f51519e84c8d703f2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built markdown-include fairscale termcolor docstring-parser jsonnet word2number sacremoses promise pathtools\n",
      "Installing collected packages: word2number, wasabi, tokenizers, termcolor, sentencepiece, py-rouge, pathtools, lmdb, jsonnet, cymem, commonmark, xxhash, urllib3, typer, traitlets, torch, spacy-loggers, spacy-legacy, smmap, smart-open, shortuuid, setproctitle, sacremoses, ruamel.yaml.clib, rfc3986, pyyaml-env-tag, pygments, pydantic, pyasn1-modules, protobuf, promise, numpy, nr.pylang.utils, nr.fs, mypy, murmurhash, mkdocs-material-extensions, mergedeep, langcodes, jsonlines, google-crc32c, ftfy, flaky, execnet, docstring-parser, docker-pycreds, Deprecated, conllu, catalogue, cachetools, base58, tensorboardX, srsly, sentry-sdk, scipy, ruamel.yaml, rich, requests, preshed, pathy, nr.util, nr.stream, Markdown, h5py, googleapis-common-protos, google-resumable-media, google-auth, gitdb, ghp-import, fairscale, botocore, blis, torchvision, thinc, responses, requests-toolbelt, readme-renderer, pytest-xdist, pytest-forked, pytest-cov, pymdown-extensions, mkdocs, markdown-include, huggingface-hub, google-api-core, GitPython, databind.core, codecov, wandb, transformers, spacy, mkdocs-material, google-cloud-core, datasets, databind.json, twine, google-cloud-storage, en-core-web-sm, docspec, databind, docspec-python, cached-path, pydoc-markdown, allennlp, allennlp-models\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.8\n",
      "    Uninstalling urllib3-1.26.8:\n",
      "      Successfully uninstalled urllib3-1.26.8\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.1\n",
      "    Uninstalling traitlets-5.1.1:\n",
      "      Successfully uninstalled traitlets-5.1.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.10.0\n",
      "    Uninstalling Pygments-2.10.0:\n",
      "      Successfully uninstalled Pygments-2.10.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.3\n",
      "    Uninstalling scipy-1.5.3:\n",
      "      Successfully uninstalled scipy-1.5.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.3.0\n",
      "    Uninstalling h5py-3.3.0:\n",
      "      Successfully uninstalled h5py-3.3.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.19\n",
      "    Uninstalling botocore-1.24.19:\n",
      "      Successfully uninstalled botocore-1.24.19\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.23.4 which is incompatible.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.96 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 GitPython-3.1.29 Markdown-3.4.1 allennlp-2.10.1 allennlp-models-2.10.1 base58-2.1.1 blis-0.7.9 botocore-1.27.96 cached-path-1.1.6 cachetools-5.2.0 catalogue-2.0.8 codecov-2.1.12 commonmark-0.9.1 conllu-4.4.2 cymem-2.0.7 databind-1.5.3 databind.core-1.5.3 databind.json-1.5.3 datasets-2.6.1 docker-pycreds-0.4.0 docspec-1.3.0 docspec-python-1.2.0 docstring-parser-0.11 en-core-web-sm-3.3.0 execnet-1.9.0 fairscale-0.4.6 flaky-3.7.0 ftfy-6.1.1 ghp-import-2.1.0 gitdb-4.0.9 google-api-core-2.10.2 google-auth-2.13.0 google-cloud-core-2.3.2 google-cloud-storage-2.5.0 google-crc32c-1.5.0 google-resumable-media-2.4.0 googleapis-common-protos-1.56.4 h5py-3.7.0 huggingface-hub-0.10.1 jsonlines-3.1.0 jsonnet-0.19.1 langcodes-3.3.0 lmdb-1.3.0 markdown-include-0.6.0 mergedeep-1.3.4 mkdocs-1.3.0 mkdocs-material-8.3.9 mkdocs-material-extensions-1.1 murmurhash-1.0.9 mypy-0.961 nr.fs-1.6.3 nr.pylang.utils-0.1.3 nr.stream-0.1.2 nr.util-0.8.12 numpy-1.23.4 pathtools-0.1.2 pathy-0.6.2 preshed-3.0.8 promise-2.3 protobuf-3.19.6 py-rouge-1.1 pyasn1-modules-0.2.8 pydantic-1.8.2 pydoc-markdown-4.5.1 pygments-2.13.0 pymdown-extensions-9.7 pytest-cov-4.0.0 pytest-forked-1.4.0 pytest-xdist-3.0.2 pyyaml-env-tag-0.1 readme-renderer-37.2 requests-2.28.1 requests-toolbelt-0.10.1 responses-0.18.0 rfc3986-2.0.0 rich-12.6.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 sacremoses-0.0.53 scipy-1.9.3 sentencepiece-0.1.97 sentry-sdk-1.10.1 setproctitle-1.3.2 shortuuid-1.0.9 smart-open-5.2.1 smmap-5.0.0 spacy-3.3.1 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.5 tensorboardX-2.5.1 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 traitlets-5.5.0 transformers-4.20.1 twine-4.0.1 typer-0.4.2 urllib3-1.26.12 wandb-0.12.21 wasabi-0.10.1 word2number-1.1 xxhash-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc65dd",
   "metadata": {},
   "source": [
    "#### get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2489eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-551641581032/sagemaker/DEMO-Allennlp/all_chapter_2.jsonl to ./all_chapter_2.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!aws s3 cp s3://sagemaker-us-east-1-551641581032/sagemaker/DEMO-Allennlp/all_chapter_2.jsonl ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98b916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-551641581032/sagemaker/DEMO-Allennlp/2375715.jsonl to ./2375715.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!aws s3 cp s3://sagemaker-us-east-1-551641581032/sagemaker/DEMO-Allennlp/2375715.jsonl ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e1af3",
   "metadata": {},
   "source": [
    "#### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a645fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375715.jsonl\t\t   infer.py    requirements.txt\n",
      "all_chapter_2.jsonl\t   lost+found  stary_dataloader.py\n",
      "allennlp-test-stary.ipynb  my.jsonnet  staryPredictor.py\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "\n",
    "#my.jsonnet: 训练配置脚本\n",
    "#stary_dataloader.py : 基于小说数据的dataloader\n",
    "#staryPredictor.py: 基于小说数据的 predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9b04f7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "2022-10-28 01:32:39,712 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-10-28 01:32:39,774 - INFO - allennlp.common.params - evaluation = None\n",
      "2022-10-28 01:32:39,774 - INFO - allennlp.common.params - include_in_archive = None\n",
      "2022-10-28 01:32:39,775 - INFO - allennlp.common.params - random_seed = 13370\n",
      "2022-10-28 01:32:39,775 - INFO - allennlp.common.params - numpy_seed = 1337\n",
      "2022-10-28 01:32:39,775 - INFO - allennlp.common.params - pytorch_seed = 133\n",
      "2022-10-28 01:32:39,776 - INFO - allennlp.common.checks - Pytorch version: 1.12.1+cu102\n",
      "2022-10-28 01:32:39,777 - INFO - allennlp.common.params - type = default\n",
      "2022-10-28 01:32:39,777 - INFO - allennlp.common.params - dataset_reader.type = stary\n",
      "2022-10-28 01:32:39,778 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-10-28 01:32:39,778 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-10-28 01:32:39,778 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-10-28 01:32:39,778 - INFO - allennlp.common.params - dataset_reader.max_span_width = 3\n",
      "2022-10-28 01:32:39,778 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2022-10-28 01:32:39,779 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-10-28 01:32:39,779 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-10-28 01:32:39,779 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-10-28 01:32:39,779 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-10-28 01:32:39,779 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "Downloading: 100%|██████████████████████████████| 414/414 [00:00<00:00, 372kB/s]\n",
      "Downloading: 100%|███████████████████████████| 208k/208k [00:00<00:00, 48.6MB/s]\n",
      "2022-10-28 01:32:40,369 - INFO - allennlp.common.params - dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2022-10-28 01:32:40,370 - INFO - allennlp.common.params - dataset_reader.max_sentences = 1\n",
      "2022-10-28 01:32:40,370 - INFO - allennlp.common.params - dataset_reader.remove_singleton_clusters = True\n",
      "2022-10-28 01:32:40,370 - INFO - allennlp.common.params - train_data_path = ./all_chapter_2.jsonl\n",
      "2022-10-28 01:32:40,370 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f25cd3c6ca0>\n",
      "2022-10-28 01:32:40,371 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
      "2022-10-28 01:32:40,371 - INFO - allennlp.common.params - validation_dataset_reader.type = staryEval\n",
      "2022-10-28 01:32:40,371 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\n",
      "2022-10-28 01:32:40,371 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\n",
      "2022-10-28 01:32:40,371 - INFO - allennlp.common.params - validation_dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-10-28 01:32:40,371 - INFO - allennlp.common.params - validation_dataset_reader.max_span_width = 3\n",
      "2022-10-28 01:32:40,372 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2022-10-28 01:32:40,372 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-10-28 01:32:40,372 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-10-28 01:32:40,372 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-10-28 01:32:40,372 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-10-28 01:32:40,372 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-10-28 01:32:40,373 - INFO - allennlp.common.params - validation_dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2022-10-28 01:32:40,373 - INFO - allennlp.common.params - validation_dataset_reader.max_sentences = None\n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - validation_dataset_reader.remove_singleton_clusters = True\n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - validation_data_path = ./2375715.jsonl\n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - validation_data_loader = None\n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - test_data_path = ./2375715.jsonl\n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - evaluate_on_test = True\n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - batch_weight_key = \n",
      "2022-10-28 01:32:40,374 - INFO - allennlp.common.params - data_loader.type = multiprocess\n",
      "2022-10-28 01:32:40,375 - INFO - allennlp.common.params - data_loader.batch_size = None\n",
      "2022-10-28 01:32:40,375 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2022-10-28 01:32:40,375 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2022-10-28 01:32:40,375 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket\n",
      "2022-10-28 01:32:40,375 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 1\n",
      "2022-10-28 01:32:40,375 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.batch_sampler.shuffle = True\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.start_method = fork\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.cuda_device = None\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.quiet = False\n",
      "2022-10-28 01:32:40,376 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x7f26010b0730>\n",
      "loading instances: 133it [00:01, 100.27it/s]\n",
      "2022-10-28 01:32:41,703 - INFO - allennlp.common.params - data_loader.type = multiprocess\n",
      "2022-10-28 01:32:41,704 - INFO - allennlp.common.params - data_loader.batch_size = None\n",
      "2022-10-28 01:32:41,704 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2022-10-28 01:32:41,704 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2022-10-28 01:32:41,704 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 1\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.batch_sampler.shuffle = True\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None\n",
      "2022-10-28 01:32:41,705 - INFO - allennlp.common.params - data_loader.start_method = fork\n",
      "2022-10-28 01:32:41,706 - INFO - allennlp.common.params - data_loader.cuda_device = None\n",
      "2022-10-28 01:32:41,706 - INFO - allennlp.common.params - data_loader.quiet = False\n",
      "2022-10-28 01:32:41,706 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x7f26010b0730>\n",
      "loading instances: 1it [00:00,  1.25it/s]\n",
      "2022-10-28 01:32:42,508 - INFO - allennlp.common.params - data_loader.type = multiprocess\n",
      "2022-10-28 01:32:42,509 - INFO - allennlp.common.params - data_loader.batch_size = None\n",
      "2022-10-28 01:32:42,509 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2022-10-28 01:32:42,509 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2022-10-28 01:32:42,509 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket\n",
      "2022-10-28 01:32:42,509 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 1\n",
      "2022-10-28 01:32:42,509 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.batch_sampler.shuffle = True\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.start_method = fork\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.cuda_device = None\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.quiet = False\n",
      "2022-10-28 01:32:42,510 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x7f26010b0730>\n",
      "loading instances: 1it [00:00,  1.07it/s]\n",
      "2022-10-28 01:32:43,447 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - min_count = None\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - max_vocab_size = None\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - pretrained_files = None\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - tokens_to_add = None\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
      "2022-10-28 01:32:43,448 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
      "2022-10-28 01:32:43,449 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
      "2022-10-28 01:32:43,449 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
      "building vocab: 135it [00:00, 10443.60it/s]\n",
      "2022-10-28 01:32:43,462 - INFO - allennlp.common.params - model.type = from_archive\n",
      "2022-10-28 01:32:43,462 - INFO - allennlp.common.params - model.archive_file = https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz\n",
      "2022-10-28 01:32:43,516 - INFO - cached_path - https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz not found in cache, downloading to /home/ec2-user/.allennlp/cache/038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213\n",
      "\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  1%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  1%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  2%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  2%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  2%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  3%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  3%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  5%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  5%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  6%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  6%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  6%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  7%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  7%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  8%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  8%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  9%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m  9%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 10%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 10%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 10%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 11%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 11%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 13%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 13%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 13%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 14%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 14%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 15%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 15%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 15%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 16%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 16%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m 17%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 17%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 17%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 18%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 18%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 19%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 19%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 19%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 20%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 20%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 20%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 21%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 21%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 22%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 22%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 22%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 23%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 23%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 24%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 24%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 24%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 25%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 25%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 26%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 26%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 26%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 27%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 27%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 28%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 28%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 28%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 29%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 29%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 30%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 30%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 30%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 30%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 31%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 31%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 32%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 32%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 32%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 33%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 33%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.4…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 34%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 34%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 34%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 35%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 35%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 35%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 36%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 36%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 37%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 37%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 37%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 38%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 38%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 39%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 39%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 39%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 40%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 40%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 40%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 41%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.5…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 41%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 42%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 42%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 42%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 42%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 43%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 45%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 45%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 45%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 46%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 46%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 46%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 47%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 47%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 48%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 48%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.6…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 48%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 49%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 49%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 49%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 51%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 51%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 51%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 53%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 53%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 55%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 55%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 55%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.7…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 56%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 56%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 58%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 58%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 59%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 59%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 60%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 60%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 60%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 61%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 61%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 61%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 62%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 62%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 62%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 63%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 63%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.8…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 63%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 64%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 64%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 65%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 65%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 66%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 66%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 66%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 67%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 67%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 68%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 68%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 68%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 69%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 69%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 69%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 70%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 70%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m0.9…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 71%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 71%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 71%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 72%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 72%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 73%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 73%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 73%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 74%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 74%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 75%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 75%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 75%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 76%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 76%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 77%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 77%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 77%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 78%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.0…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 78%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 79%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 79%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 80%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 80%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 80%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 81%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 81%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 81%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 82%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 82%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 83%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 83%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 83%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 84%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 84%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 85%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 85%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.1…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 86%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 86%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 86%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 87%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 87%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 88%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 88%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 88%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 89%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 89%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 90%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 90%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 91%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 91%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 91%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 92%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 92%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 93%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.2…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 93%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 94%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 94%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 95%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 95%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 95%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 96%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 96%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 97%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 97%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 98%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 98%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36mhttps://storage.googleapis.com/allennlp-public-mo…\u001b[0m \u001b[90m━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:…\u001b[0m \u001b[32m1.3…\u001b[0m\n",
      "                                                                            \u001b[32mGB  \u001b[0m\n",
      "\u001b[?25h2022-10-28 01:33:11,099 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz from cache at /home/ec2-user/.allennlp/cache/038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213\n",
      "2022-10-28 01:33:11,100 - INFO - allennlp.models.archival - extracting archive file /home/ec2-user/.allennlp/cache/038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213 to temp dir /tmp/tmphxqdzyac\n",
      "2022-10-28 01:33:24,213 - INFO - allennlp.common.params - dataset_reader.type = coref\n",
      "2022-10-28 01:33:24,214 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-10-28 01:33:24,214 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-10-28 01:33:24,214 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-10-28 01:33:24,214 - INFO - allennlp.common.params - dataset_reader.max_span_width = 30\n",
      "2022-10-28 01:33:24,214 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2022-10-28 01:33:24,215 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-10-28 01:33:24,215 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-10-28 01:33:24,215 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-10-28 01:33:24,215 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-10-28 01:33:24,215 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-10-28 01:33:24,217 - INFO - allennlp.common.params - dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2022-10-28 01:33:24,217 - INFO - allennlp.common.params - dataset_reader.max_sentences = 110\n",
      "2022-10-28 01:33:24,217 - INFO - allennlp.common.params - dataset_reader.remove_singleton_clusters = False\n",
      "2022-10-28 01:33:24,217 - INFO - allennlp.common.params - validation_dataset_reader.type = coref\n",
      "2022-10-28 01:33:24,217 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\n",
      "2022-10-28 01:33:24,218 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\n",
      "2022-10-28 01:33:24,218 - INFO - allennlp.common.params - validation_dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-10-28 01:33:24,218 - INFO - allennlp.common.params - validation_dataset_reader.max_span_width = 30\n",
      "2022-10-28 01:33:24,218 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2022-10-28 01:33:24,218 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-10-28 01:33:24,219 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-10-28 01:33:24,219 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-10-28 01:33:24,219 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-10-28 01:33:24,219 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-10-28 01:33:24,220 - INFO - allennlp.common.params - validation_dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2022-10-28 01:33:24,220 - INFO - allennlp.common.params - validation_dataset_reader.max_sentences = None\n",
      "2022-10-28 01:33:24,220 - INFO - allennlp.common.params - validation_dataset_reader.remove_singleton_clusters = False\n",
      "2022-10-28 01:33:24,221 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-10-28 01:33:24,221 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmphxqdzyac/vocabulary.\n",
      "2022-10-28 01:33:24,222 - INFO - allennlp.common.params - model.type = coref\n",
      "2022-10-28 01:33:24,222 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-10-28 01:33:24,222 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-10-28 01:33:24,222 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2022-10-28 01:33:24,223 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched\n",
      "2022-10-28 01:33:24,223 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2022-10-28 01:33:24,223 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\n",
      "2022-10-28 01:33:24,223 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.load_weights = True\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None\n",
      "2022-10-28 01:33:24,224 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None\n",
      "2022-10-28 01:33:24,225 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_token_mode = avg\n",
      "Downloading: 100%|███████████████████████████| 634M/634M [00:08<00:00, 79.8MB/s]\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-10-28 01:33:36,542 - INFO - allennlp.common.params - model.context_layer.type = pass_through\n",
      "2022-10-28 01:33:36,542 - INFO - allennlp.common.params - model.context_layer.input_dim = 1024\n",
      "2022-10-28 01:33:36,543 - INFO - allennlp.common.params - model.mention_feedforward.input_dim = 3092\n",
      "2022-10-28 01:33:36,543 - INFO - allennlp.common.params - model.mention_feedforward.num_layers = 2\n",
      "2022-10-28 01:33:36,543 - INFO - allennlp.common.params - model.mention_feedforward.hidden_dims = 1500\n",
      "2022-10-28 01:33:36,543 - INFO - allennlp.common.params - model.mention_feedforward.activations = relu\n",
      "2022-10-28 01:33:36,543 - INFO - allennlp.common.params - type = relu\n",
      "2022-10-28 01:33:36,543 - INFO - allennlp.common.params - model.mention_feedforward.dropout = 0.3\n",
      "2022-10-28 01:33:36,607 - INFO - allennlp.common.params - model.antecedent_feedforward.input_dim = 9296\n",
      "2022-10-28 01:33:36,607 - INFO - allennlp.common.params - model.antecedent_feedforward.num_layers = 2\n",
      "2022-10-28 01:33:36,607 - INFO - allennlp.common.params - model.antecedent_feedforward.hidden_dims = 1500\n",
      "2022-10-28 01:33:36,607 - INFO - allennlp.common.params - model.antecedent_feedforward.activations = relu\n",
      "2022-10-28 01:33:36,608 - INFO - allennlp.common.params - type = relu\n",
      "2022-10-28 01:33:36,608 - INFO - allennlp.common.params - model.antecedent_feedforward.dropout = 0.3\n",
      "2022-10-28 01:33:36,755 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2022-10-28 01:33:36,755 - INFO - allennlp.common.params - model.max_span_width = 30\n",
      "2022-10-28 01:33:36,755 - INFO - allennlp.common.params - model.spans_per_word = 0.4\n",
      "2022-10-28 01:33:36,755 - INFO - allennlp.common.params - model.max_antecedents = 50\n",
      "2022-10-28 01:33:36,755 - INFO - allennlp.common.params - model.coarse_to_fine = True\n",
      "2022-10-28 01:33:36,756 - INFO - allennlp.common.params - model.inference_order = 2\n",
      "2022-10-28 01:33:36,756 - INFO - allennlp.common.params - model.lexical_dropout = 0.2\n",
      "2022-10-28 01:33:36,756 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f25cd2ef9a0>\n",
      "2022-10-28 01:33:36,844 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.weight\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.weight\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.weight\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.bias\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.weight\n",
      "2022-10-28 01:33:36,846 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.bias\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _distance_embedding.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.bias\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.bias\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _mention_scorer._module.bias\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _mention_scorer._module.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.bias\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-10-28 01:33:36,847 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,848 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,849 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-10-28 01:33:36,850 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-10-28 01:33:36,851 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.weight\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.bias\n",
      "2022-10-28 01:33:36,852 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.bias\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.weight\n",
      "2022-10-28 01:33:36,853 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.bias\n",
      "2022-10-28 01:33:36,854 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,855 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,856 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.weight\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,857 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.bias\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.weight\n",
      "2022-10-28 01:33:36,858 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.bias\n",
      "2022-10-28 01:33:36,859 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,860 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,861 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.weight\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,862 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.bias\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.weight\n",
      "2022-10-28 01:33:36,863 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.bias\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.weight\n",
      "2022-10-28 01:33:36,864 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.weight\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.bias\n",
      "2022-10-28 01:33:36,865 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-10-28 01:33:36,866 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-10-28 01:33:36,867 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,868 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,869 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-10-28 01:33:36,870 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-10-28 01:33:36,871 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,872 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-10-28 01:33:36,873 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-10-28 01:33:36,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-10-28 01:33:36,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-10-28 01:33:36,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-10-28 01:33:36,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-10-28 01:33:36,874 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-10-28 01:33:36,880 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-10-28 01:33:36,880 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-10-28 01:33:37,960 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmphxqdzyac\n",
      "2022-10-28 01:33:38,084 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-10-28 01:33:38,084 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-10-28 01:33:39,431 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
      "2022-10-28 01:33:39,431 - INFO - allennlp.common.params - trainer.cuda_device = None\n",
      "2022-10-28 01:33:39,431 - INFO - allennlp.common.params - trainer.distributed = False\n",
      "2022-10-28 01:33:39,431 - INFO - allennlp.common.params - trainer.world_size = 1\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.patience = 5\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.validation_metric = +coref_f1\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.grad_norm = False\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
      "2022-10-28 01:33:39,432 - INFO - allennlp.common.params - trainer.use_amp = False\n",
      "2022-10-28 01:33:39,433 - INFO - allennlp.common.params - trainer.no_grad = None\n",
      "2022-10-28 01:33:39,433 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2022-10-28 01:33:39,433 - INFO - allennlp.common.params - trainer.moving_average = None\n",
      "2022-10-28 01:33:39,433 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x7f25cd417370>\n",
      "2022-10-28 01:33:39,433 - INFO - allennlp.common.params - trainer.callbacks = None\n",
      "2022-10-28 01:33:39,433 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True\n",
      "2022-10-28 01:33:39,434 - INFO - allennlp.common.params - trainer.run_confidence_checks = True\n",
      "2022-10-28 01:33:39,434 - INFO - allennlp.common.params - trainer.grad_scaling = True\n",
      "2022-10-28 01:33:43,318 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw\n",
      "2022-10-28 01:33:43,319 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0003\n",
      "2022-10-28 01:33:43,319 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
      "2022-10-28 01:33:43,319 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
      "2022-10-28 01:33:43,319 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0\n",
      "2022-10-28 01:33:43,319 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True\n",
      "2022-10-28 01:33:43,321 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
      "2022-10-28 01:33:43,321 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight'], {'lr': 1e-05}\n",
      "2022-10-28 01:33:43,325 - INFO - allennlp.training.optimizers - Group 1: ['_coarse2fine_scorer.bias', '_antecedent_scorer._module.weight', '_antecedent_feedforward._module._linear_layers.0.weight', '_span_updating_gated_sum._gate.weight', '_antecedent_feedforward._module._linear_layers.1.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_mention_feedforward._module._linear_layers.0.weight', '_antecedent_feedforward._module._linear_layers.1.weight', '_antecedent_scorer._module.bias', '_mention_scorer._module.weight', '_span_updating_gated_sum._gate.bias', '_distance_embedding.weight', '_antecedent_feedforward._module._linear_layers.0.bias', '_mention_feedforward._module._linear_layers.1.bias', '_attentive_span_extractor._global_attention._module.bias', '_mention_feedforward._module._linear_layers.0.bias', '_mention_feedforward._module._linear_layers.1.weight', '_attentive_span_extractor._global_attention._module.weight', '_coarse2fine_scorer.weight', '_mention_scorer._module.bias'], {}\n",
      "2022-10-28 01:33:43,327 - INFO - allennlp.training.optimizers - Number of trainable parameters: 366241832\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "2022-10-28 01:33:43,330 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-10-28 01:33:43,332 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,333 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-10-28 01:33:43,334 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-10-28 01:33:43,335 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,336 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,337 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-10-28 01:33:43,338 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-10-28 01:33:43,339 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,340 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-10-28 01:33:43,341 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-10-28 01:33:43,342 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,343 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-10-28 01:33:43,344 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,345 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,346 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,347 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-10-28 01:33:43,348 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.weight\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.bias\n",
      "2022-10-28 01:33:43,349 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.bias\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.bias\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.bias\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,350 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.weight\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.weight\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.weight\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,351 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.weight\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.bias\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.weight\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.bias\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.weight\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.bias\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.weight\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.bias\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,352 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.bias\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.bias\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.bias\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.weight\n",
      "2022-10-28 01:33:43,353 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.weight\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.weight\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.bias\n",
      "2022-10-28 01:33:43,354 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.bias\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.bias\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.bias\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,355 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.weight\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.bias\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.weight\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.bias\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.weight\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.bias\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,356 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.weight\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.weight\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.weight\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.weight\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,357 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.bias\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.bias\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.bias\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.weight\n",
      "2022-10-28 01:33:43,358 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.weight\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.weight\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.bias\n",
      "2022-10-28 01:33:43,359 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.weight\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.bias\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.weight\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.bias\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.weight\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.bias\n",
      "2022-10-28 01:33:43,360 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.bias\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.bias\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.bias\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,361 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.weight\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.weight\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.weight\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.weight\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,362 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.bias\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.bias\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.bias\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.weight\n",
      "2022-10-28 01:33:43,363 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.bias\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.weight\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.bias\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.weight\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.bias\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.weight\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.bias\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.weight\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.bias\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-10-28 01:33:43,364 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.0.weight\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.0.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.1.weight\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.1.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _mention_scorer._module.weight\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _mention_scorer._module.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.0.weight\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.1.weight\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _antecedent_scorer._module.weight\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _antecedent_scorer._module.bias\n",
      "2022-10-28 01:33:43,365 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _attentive_span_extractor._global_attention._module.weight\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _attentive_span_extractor._global_attention._module.bias\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _distance_embedding.weight\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _coarse2fine_scorer.weight\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _coarse2fine_scorer.bias\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _span_updating_gated_sum._gate.weight\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.util - _span_updating_gated_sum._gate.bias\n",
      "2022-10-28 01:33:43,366 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.06\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
      "2022-10-28 01:33:43,367 - INFO - allennlp.common.params - type = default\n",
      "2022-10-28 01:33:43,368 - INFO - allennlp.common.params - save_completed_epochs = True\n",
      "2022-10-28 01:33:43,368 - INFO - allennlp.common.params - save_every_num_seconds = None\n",
      "2022-10-28 01:33:43,368 - INFO - allennlp.common.params - save_every_num_batches = None\n",
      "2022-10-28 01:33:43,368 - INFO - allennlp.common.params - keep_most_recent_by_count = 2\n",
      "2022-10-28 01:33:43,368 - INFO - allennlp.common.params - keep_most_recent_by_age = None\n",
      "2022-10-28 01:33:43,371 - INFO - allennlp.training.gradient_descent_trainer - Beginning training.\n",
      "2022-10-28 01:33:43,371 - INFO - allennlp.training.gradient_descent_trainer - Epoch 0/9\n",
      "2022-10-28 01:33:43,371 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/torch/cuda/memory.py:278: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "2022-10-28 01:33:43,372 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 1.4G\n",
      "2022-10-28 01:33:43,374 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "  0%|          | 0/133 [00:00<?, ?it/s]2022-10-28 01:33:47,557 - INFO - allennlp.training.callbacks.console_logger - Batch inputs\n",
      "2022-10-28 01:33:47,558 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/token_ids (Shape: 1 x 144)\n",
      "tensor([[ 101, 1114, 1103,  ..., 6269, 1115,  102]], device='cuda:0')\n",
      "2022-10-28 01:33:47,559 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/mask (Shape: 1 x 133)\n",
      "tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n",
      "2022-10-28 01:33:47,560 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/type_ids (Shape: 1 x 144)\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "2022-10-28 01:33:47,561 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/wordpiece_mask (Shape: 1 x 144)\n",
      "tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n",
      "2022-10-28 01:33:47,562 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/segment_concat_mask (Shape: 1 x 144)\n",
      "tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n",
      "2022-10-28 01:33:47,563 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/offsets (Shape: 1 x 133 x 2)\n",
      "tensor([[[  1,   1],\n",
      "         [  2,   2],\n",
      "         [  3,   4],\n",
      "         ...,\n",
      "         [139, 140],\n",
      "         [141, 141],\n",
      "         [142, 142]]], device='cuda:0')\n",
      "2022-10-28 01:33:47,564 - INFO - allennlp.training.callbacks.console_logger - batch_input/spans (Shape: 1 x 396 x 2)\n",
      "tensor([[[  0,   0],\n",
      "         [  0,   1],\n",
      "         [  0,   2],\n",
      "         ...,\n",
      "         [131, 131],\n",
      "         [131, 132],\n",
      "         [132, 132]]], device='cuda:0')\n",
      "2022-10-28 01:33:47,566 - INFO - allennlp.training.callbacks.console_logger - Field : \"batch_input/metadata\" : (Length 1 of type \"<class 'dict'>\")\n",
      "2022-10-28 01:33:47,566 - INFO - allennlp.training.callbacks.console_logger - batch_input/span_labels (Shape: 1 x 396)\n",
      "tensor([[-1, -1, -1,  ..., -1, -1, -1]], device='cuda:0')\n",
      "coref_precision: 0.6321, coref_recall: 0.6676, coref_f1: 0.6471, mention_recall: 0.9481, batch_loss: 17.1778, loss: 26.6232 ||: 100%|##########| 133/133 [00:22<00:00,  5.80it/s]\n",
      "2022-10-28 01:34:06,288 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/allennlp/modules/token_embedders/pretrained_transformer_embedder.py:385: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  num_effective_segments = (seq_lengths + self._max_length - 1) // self._max_length\n",
      "2022-10-28 01:34:06,837 - INFO - allennlp.training.callbacks.console_logger - Batch inputs\n",
      "2022-10-28 01:34:06,838 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/token_ids (Shape: 1 x 2827)\n",
      "tensor([[ 101,  122,  119,  ..., 1122,  106,  102]], device='cuda:0')\n",
      "2022-10-28 01:34:06,839 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/mask (Shape: 1 x 2635)\n",
      "tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n",
      "2022-10-28 01:34:06,840 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/type_ids (Shape: 1 x 2827)\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "2022-10-28 01:34:06,841 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/wordpiece_mask (Shape: 1 x 2817)\n",
      "tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n",
      "2022-10-28 01:34:06,842 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/segment_concat_mask (Shape: 1 x 2827)\n",
      "tensor([[True, True, True,  ..., True, True, True]], device='cuda:0')\n",
      "2022-10-28 01:34:06,843 - INFO - allennlp.training.callbacks.console_logger - batch_input/text/tokens/offsets (Shape: 1 x 2635 x 2)\n",
      "tensor([[[   1,    1],\n",
      "         [   2,    2],\n",
      "         [   3,    3],\n",
      "         ...,\n",
      "         [2813, 2813],\n",
      "         [2814, 2814],\n",
      "         [2815, 2815]]], device='cuda:0')\n",
      "2022-10-28 01:34:06,844 - INFO - allennlp.training.callbacks.console_logger - batch_input/spans (Shape: 1 x 7902 x 2)\n",
      "tensor([[[   0,    0],\n",
      "         [   0,    1],\n",
      "         [   0,    2],\n",
      "         ...,\n",
      "         [2633, 2633],\n",
      "         [2633, 2634],\n",
      "         [2634, 2634]]], device='cuda:0')\n",
      "2022-10-28 01:34:06,846 - INFO - allennlp.training.callbacks.console_logger - Field : \"batch_input/metadata\" : (Length 1 of type \"<class 'dict'>\")\n",
      "2022-10-28 01:34:06,846 - INFO - allennlp.training.callbacks.console_logger - batch_input/span_labels (Shape: 1 x 7902)\n",
      "tensor([[-1, -1, -1,  ..., -1, -1, -1]], device='cuda:0')\n",
      "coref_precision: 0.6122, coref_recall: 0.6079, coref_f1: 0.5887, mention_recall: 0.9066, batch_loss: 301.6232, loss: 301.6232 ||: 100%|##########| 1/1 [00:00<00:00,  1.80it/s]\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.647  |     0.589\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.632  |     0.612\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.668  |     0.608\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  1398.964  |       N/A\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - loss               |    26.623  |   301.623\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.948  |     0.907\n",
      "2022-10-28 01:34:06,848 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:34:13,651 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:30.279389\n",
      "2022-10-28 01:34:13,651 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:03:31\n",
      "2022-10-28 01:34:13,651 - INFO - allennlp.training.gradient_descent_trainer - Epoch 1/9\n",
      "2022-10-28 01:34:13,651 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:34:13,651 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:34:13,654 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.7765, coref_recall: 0.7272, coref_f1: 0.7504, mention_recall: 0.9679, batch_loss: 6.1206, loss: 8.6614 ||: 100%|##########| 133/133 [00:18<00:00,  7.06it/s] \n",
      "2022-10-28 01:34:32,487 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.5900, coref_recall: 0.5204, coref_f1: 0.4917, mention_recall: 0.9446, batch_loss: 297.9023, loss: 297.9023 ||: 100%|##########| 1/1 [00:00<00:00,  1.83it/s]\n",
      "2022-10-28 01:34:33,036 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.750  |     0.492\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.776  |     0.590\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.727  |     0.520\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - loss               |     8.661  |   297.902\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.968  |     0.945\n",
      "2022-10-28 01:34:33,037 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:34:39,884 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:26.233399\n",
      "2022-10-28 01:34:39,885 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:03:18\n",
      "2022-10-28 01:34:39,885 - INFO - allennlp.training.gradient_descent_trainer - Epoch 2/9\n",
      "2022-10-28 01:34:39,885 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:34:39,885 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:34:39,887 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.8390, coref_recall: 0.8067, coref_f1: 0.8221, mention_recall: 0.9833, batch_loss: 3.5358, loss: 6.1101 ||: 100%|##########| 133/133 [00:18<00:00,  7.07it/s] \n",
      "2022-10-28 01:34:58,701 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.5898, coref_recall: 0.7050, coref_f1: 0.6154, mention_recall: 0.9481, batch_loss: 329.1231, loss: 329.1231 ||: 100%|##########| 1/1 [00:00<00:00,  1.83it/s]\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.822  |     0.615\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.839  |     0.590\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.807  |     0.705\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - loss               |     6.110  |   329.123\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.983  |     0.948\n",
      "2022-10-28 01:34:59,251 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:35:06,649 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:26.764416\n",
      "2022-10-28 01:35:06,649 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:02:57\n",
      "2022-10-28 01:35:06,649 - INFO - allennlp.training.gradient_descent_trainer - Epoch 3/9\n",
      "2022-10-28 01:35:06,650 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:35:06,650 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:35:06,652 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.8869, coref_recall: 0.8605, coref_f1: 0.8734, mention_recall: 0.9870, batch_loss: 0.6619, loss: 4.1738 ||: 100%|##########| 133/133 [00:19<00:00,  6.97it/s] \n",
      "2022-10-28 01:35:25,736 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.5900, coref_recall: 0.7045, coref_f1: 0.6289, mention_recall: 0.9585, batch_loss: 350.1654, loss: 350.1654 ||: 100%|##########| 1/1 [00:00<00:00,  1.82it/s]\n",
      "2022-10-28 01:35:26,287 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.873  |     0.629\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.887  |     0.590\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.861  |     0.704\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - loss               |     4.174  |   350.165\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.987  |     0.958\n",
      "2022-10-28 01:35:26,288 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:35:33,932 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:27.282517\n",
      "2022-10-28 01:35:33,932 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:02:34\n",
      "2022-10-28 01:35:33,932 - INFO - allennlp.training.gradient_descent_trainer - Epoch 4/9\n",
      "2022-10-28 01:35:33,933 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:35:33,933 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:35:33,936 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.9314, coref_recall: 0.9022, coref_f1: 0.9166, mention_recall: 0.9889, batch_loss: 0.6216, loss: 2.8809 ||: 100%|##########| 133/133 [00:19<00:00,  7.00it/s]\n",
      "2022-10-28 01:35:52,941 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.6049, coref_recall: 0.7408, coref_f1: 0.6463, mention_recall: 0.9550, batch_loss: 394.6824, loss: 394.6824 ||: 100%|##########| 1/1 [00:00<00:00,  1.45it/s]\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.917  |     0.646\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.931  |     0.605\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.902  |     0.741\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - loss               |     2.881  |   394.682\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.989  |     0.955\n",
      "2022-10-28 01:35:53,635 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:36:01,009 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:27.076603\n",
      "2022-10-28 01:36:01,009 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:02:10\n",
      "2022-10-28 01:36:01,009 - INFO - allennlp.training.gradient_descent_trainer - Epoch 5/9\n",
      "2022-10-28 01:36:01,009 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:36:01,010 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:36:01,012 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.9533, coref_recall: 0.9266, coref_f1: 0.9398, mention_recall: 0.9883, batch_loss: 0.6620, loss: 1.9856 ||: 100%|##########| 133/133 [00:19<00:00,  6.99it/s]\n",
      "2022-10-28 01:36:20,043 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.6096, coref_recall: 0.6945, coref_f1: 0.6281, mention_recall: 0.9619, batch_loss: 451.4385, loss: 451.4385 ||: 100%|##########| 1/1 [00:00<00:00,  1.80it/s]\n",
      "2022-10-28 01:36:20,602 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:36:20,602 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.940  |     0.628\n",
      "2022-10-28 01:36:20,602 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.953  |     0.610\n",
      "2022-10-28 01:36:20,602 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.927  |     0.695\n",
      "2022-10-28 01:36:20,602 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:36:20,602 - INFO - allennlp.training.callbacks.console_logger - loss               |     1.986  |   451.438\n",
      "2022-10-28 01:36:20,603 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.962\n",
      "2022-10-28 01:36:20,603 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:36:28,204 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:27.194749\n",
      "2022-10-28 01:36:28,204 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:01:44\n",
      "2022-10-28 01:36:28,205 - INFO - allennlp.training.gradient_descent_trainer - Epoch 6/9\n",
      "2022-10-28 01:36:28,205 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:36:28,205 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:36:28,207 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.9721, coref_recall: 0.9477, coref_f1: 0.9598, mention_recall: 0.9901, batch_loss: 0.1122, loss: 1.2046 ||: 100%|##########| 133/133 [00:18<00:00,  7.02it/s]\n",
      "2022-10-28 01:36:47,155 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.6246, coref_recall: 0.7245, coref_f1: 0.6536, mention_recall: 0.9654, batch_loss: 488.5327, loss: 488.5327 ||: 100%|##########| 1/1 [00:00<00:00,  1.81it/s]\n",
      "2022-10-28 01:36:47,711 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:36:47,711 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.960  |     0.654\n",
      "2022-10-28 01:36:47,711 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.972  |     0.625\n",
      "2022-10-28 01:36:47,711 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.948  |     0.724\n",
      "2022-10-28 01:36:47,712 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:36:47,712 - INFO - allennlp.training.callbacks.console_logger - loss               |     1.205  |   488.533\n",
      "2022-10-28 01:36:47,712 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.990  |     0.965\n",
      "2022-10-28 01:36:47,712 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:36:55,123 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:26.918739\n",
      "2022-10-28 01:36:55,124 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:01:19\n",
      "2022-10-28 01:36:55,124 - INFO - allennlp.training.gradient_descent_trainer - Epoch 7/9\n",
      "2022-10-28 01:36:55,124 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:36:55,124 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:36:55,127 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.9754, coref_recall: 0.9531, coref_f1: 0.9641, mention_recall: 0.9907, batch_loss: 1.1895, loss: 1.0057 ||: 100%|##########| 133/133 [00:19<00:00,  6.98it/s]\n",
      "2022-10-28 01:37:14,173 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.6109, coref_recall: 0.7308, coref_f1: 0.6472, mention_recall: 0.9619, batch_loss: 496.6512, loss: 496.6512 ||: 100%|##########| 1/1 [00:00<00:00,  1.80it/s]\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.964  |     0.647\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.975  |     0.611\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.953  |     0.731\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - loss               |     1.006  |   496.651\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.991  |     0.962\n",
      "2022-10-28 01:37:14,732 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:37:22,525 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:27.401078\n",
      "2022-10-28 01:37:22,525 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:00:52\n",
      "2022-10-28 01:37:22,525 - INFO - allennlp.training.gradient_descent_trainer - Epoch 8/9\n",
      "2022-10-28 01:37:22,525 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:37:22,526 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:37:22,528 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.9850, coref_recall: 0.9607, coref_f1: 0.9727, mention_recall: 0.9901, batch_loss: 0.1804, loss: 0.7031 ||: 100%|##########| 133/133 [00:19<00:00,  6.97it/s]\n",
      "2022-10-28 01:37:41,598 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.6352, coref_recall: 0.7227, coref_f1: 0.6607, mention_recall: 0.9654, batch_loss: 514.8180, loss: 514.8180 ||: 100%|##########| 1/1 [00:00<00:00,  1.81it/s]\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.973  |     0.661\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.985  |     0.635\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.961  |     0.723\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.703  |   514.818\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.990  |     0.965\n",
      "2022-10-28 01:37:42,154 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:37:49,532 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:27.006881\n",
      "2022-10-28 01:37:49,532 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 0:00:26\n",
      "2022-10-28 01:37:49,532 - INFO - allennlp.training.gradient_descent_trainer - Epoch 9/9\n",
      "2022-10-28 01:37:49,533 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 5.1G\n",
      "2022-10-28 01:37:49,533 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 9.6G\n",
      "2022-10-28 01:37:49,536 - INFO - allennlp.training.gradient_descent_trainer - Training\n",
      "coref_precision: 0.9892, coref_recall: 0.9666, coref_f1: 0.9777, mention_recall: 0.9907, batch_loss: 2.9135, loss: 0.6042 ||: 100%|##########| 133/133 [00:19<00:00,  7.00it/s]\n",
      "2022-10-28 01:38:08,547 - INFO - allennlp.training.gradient_descent_trainer - Validating\n",
      "coref_precision: 0.6367, coref_recall: 0.7294, coref_f1: 0.6649, mention_recall: 0.9654, batch_loss: 528.6866, loss: 528.6866 ||: 100%|##########| 1/1 [00:00<00:00,  1.80it/s]\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.978  |     0.665\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.989  |     0.637\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.967  |     0.729\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  9850.614  |       N/A\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.604  |   528.687\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.991  |     0.965\n",
      "2022-10-28 01:38:09,106 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  5222.176  |       N/A\n",
      "2022-10-28 01:38:16,799 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:00:27.266433\n",
      "2022-10-28 01:38:16,799 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n",
      "2022-10-28 01:38:16,802 - INFO - allennlp.training.util - Iterating over dataset\n",
      "coref_precision: 0.64, coref_recall: 0.73, coref_f1: 0.66, mention_recall: 0.97, loss: 528.69 ||: : 1it [00:00,  1.76it/s]\n",
      "2022-10-28 01:38:17,369 - INFO - allennlp.common.util - Metrics: {\n",
      "  \"best_epoch\": 9,\n",
      "  \"peak_worker_0_memory_MB\": 5222.17578125,\n",
      "  \"peak_gpu_0_memory_MB\": 9850.6142578125,\n",
      "  \"training_duration\": \"0:04:25.734409\",\n",
      "  \"epoch\": 9,\n",
      "  \"training_coref_precision\": 0.9891596401449769,\n",
      "  \"training_coref_recall\": 0.9665567275168727,\n",
      "  \"training_coref_f1\": 0.9777189890745328,\n",
      "  \"training_mention_recall\": 0.9907292954264524,\n",
      "  \"training_loss\": 0.6041537818285116,\n",
      "  \"training_worker_0_memory_MB\": 5222.17578125,\n",
      "  \"training_gpu_0_memory_MB\": 9850.6142578125,\n",
      "  \"validation_coref_precision\": 0.6367120539095193,\n",
      "  \"validation_coref_recall\": 0.7294367881356284,\n",
      "  \"validation_coref_f1\": 0.6648899554745227,\n",
      "  \"validation_mention_recall\": 0.9653979238754326,\n",
      "  \"validation_loss\": 528.6866455078125,\n",
      "  \"best_validation_coref_precision\": 0.6367120539095193,\n",
      "  \"best_validation_coref_recall\": 0.7294367881356284,\n",
      "  \"best_validation_coref_f1\": 0.6648899554745227,\n",
      "  \"best_validation_mention_recall\": 0.9653979238754326,\n",
      "  \"best_validation_loss\": 528.6866455078125,\n",
      "  \"test_coref_precision\": 0.6367120539095193,\n",
      "  \"test_coref_recall\": 0.7294367881356284,\n",
      "  \"test_coref_f1\": 0.6648899554745227,\n",
      "  \"test_mention_recall\": 0.9653979238754326,\n",
      "  \"test_loss\": 528.6866455078125\n",
      "}\n",
      "2022-10-28 01:38:17,370 - INFO - allennlp.models.archival - archiving weights and vocabulary to ./model_save/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#基于allennlp命令进行模型训练\n",
    "!allennlp train my.jsonnet -s ./model_save -f --include-package stary_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab25b0",
   "metadata": {},
   "source": [
    "#### Deploy the trained model to prepare for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0317c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-Allennlp'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b018afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir tmp\n",
    "#!mkdir tmp/code\n",
    "!cp ./model_save/model.tar.gz ./tmp/\n",
    "!cp requirements.txt ./tmp/code/\n",
    "!cp stary_dataloader.py ./tmp/code/\n",
    "!cp staryPredictor.py ./tmp/code/\n",
    "!cp infer.py ./tmp/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d72e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/stary_dataloader.py\n",
      "code/requirements.txt\n",
      "code/staryPredictor.py\n",
      "code/infer.py\n",
      "code/.ipynb_checkpoints/\n",
      "model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!cd tmp && tar -czvf ../model-inference.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aee52d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model-inference.tar.gz to s3://sagemaker-us-east-1-551641581032/output/model-inference.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model-inference.tar.gz s3://$bucket/output/model-inference.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b57f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data='s3://sagemaker-us-east-1-551641581032/output/model-inference.tar.gz',\n",
    "                             role=role,\n",
    "                             entry_point='infer.py',\n",
    "                             framework_version='1.9.0', py_version='py38',\n",
    "                              model_server_workers=1)\n",
    "\n",
    "instance_type = 'ml.m5.2xlarge'\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19405a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Endpoints\": [\n",
      "        {\n",
      "            \"EndpointName\": \"pytorch-inference-2022-10-28-03-03-15-084\",\n",
      "            \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:551641581032:endpoint/pytorch-inference-2022-10-28-03-03-15-084\",\n",
      "            \"CreationTime\": 1666926195.367,\n",
      "            \"LastModifiedTime\": 1666926578.258,\n",
      "            \"EndpointStatus\": \"InService\"\n",
      "        },\n",
      "        {\n",
      "            \"EndpointName\": \"pytorch-inference-2022-10-28-01-11-59-594\",\n",
      "            \"EndpointArn\": \"arn:aws:sagemaker:us-east-1:551641581032:endpoint/pytorch-inference-2022-10-28-01-11-59-594\",\n",
      "            \"CreationTime\": 1666919519.871,\n",
      "            \"LastModifiedTime\": 1666919965.846,\n",
      "            \"EndpointStatus\": \"InService\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker list-endpoints --status-equals InService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0865be",
   "metadata": {},
   "source": [
    "#### Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890034e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint_name = 'pytorch-inference-2022-10-28-03-03-15-084'  # 'ml.m5.2xlarge'\n",
    "#predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c75537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca819a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  {'doc': '\" After a long discussion about it . Selene \\'s brother , Helios , came up with a compromise . \\' Alright , Selene , they shall have a chance for change . For now , you will pair them with their own races , but when the time comes you will choose a pure - hearted female to be your Moon Princess . She will have three mates , one of her own kind and two of different races . If she can bring three races together with her mates , then we will not destroy them . \\' Selene was happy that her children were given a chance . \"', 'clusters': [[[8, 8], [23, 23], [36, 36], [50, 50], [60, 60], [100, 100], [104, 104]], [[64, 64], [72, 72], [82, 82], [89, 89]]]}\n",
      "time: 0.6020877361297607\n"
     ]
    }
   ],
   "source": [
    "texts = \"After a long discussion about it. Selene's brother, Helios, came up with a compromise. 'Alright, Selene, they shall have a chance for change. For now, you will pair them with their own races, but when the time comes you will choose a pure-hearted female to be your Moon Princess. She will have three mates, one of her own kind and two of different races. If she can bring three races together with her mates, then we will not destroy them.' Selene was happy that her children were given a chance.\"\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "outputs = predictor.predict(texts)\n",
    "end = time.time()\n",
    "print('outputs: ', outputs)\n",
    "print('time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85886404",
   "metadata": {},
   "source": [
    "#### clean-up\n",
    "Deleting the local endpoint when you're finished is important since you can only run one local endpoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c605ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13081be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
